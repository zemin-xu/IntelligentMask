{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ct.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMks+DXDVGeK7550WiLaPkn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjnMpaxaFWhk","executionInfo":{"status":"ok","timestamp":1617567957764,"user_tz":-120,"elapsed":6732,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}},"outputId":"8af435bc-501c-4282-871e-17f786563d24"},"source":["!pip install --upgrade coremltools"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting coremltools\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/b0/14c37edf39a9b32c2c9c7aa3e27ece4ef4f5b2dd2c950102661a106520f1/coremltools-4.1-cp37-none-manylinux1_x86_64.whl (3.4MB)\n","\u001b[K     |████████████████████████████████| 3.4MB 12.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<1.20,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.4.1)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools) (4.41.1)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.15.0)\n","Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.7/dist-packages (from coremltools) (20.3.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (3.12.4)\n","Collecting attr\n","  Downloading https://files.pythonhosted.org/packages/de/be/ddc7f84d4e087144472a38a373d3e319f51a6faf6e5fc1ae897173675f21/attr-0.3.1.tar.gz\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools) (20.9)\n","Requirement already satisfied, skipping upgrade: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.7.1)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->coremltools) (54.2.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools) (2.4.7)\n","Requirement already satisfied, skipping upgrade: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools) (1.2.1)\n","Building wheels for collected packages: attr\n","  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for attr: filename=attr-0.3.1-cp37-none-any.whl size=2458 sha256=2528d1b4cbcb289382d0c0ec3b7abce7f01753d1717cf1f0204a271383459e00\n","  Stored in directory: /root/.cache/pip/wheels/f0/96/9b/1f8892a707d17095b5a6eab0275da9d39e68e03a26aee2e726\n","Successfully built attr\n","Installing collected packages: attr, coremltools\n","Successfully installed attr-0.3.1 coremltools-4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjNFeQODFcKk","executionInfo":{"status":"ok","timestamp":1617567961172,"user_tz":-120,"elapsed":10132,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}},"outputId":"0a0adf35-fcc5-4415-d39a-c921b1f3f30d"},"source":["pip install torch torchvision torchaudio"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n","Collecting torchaudio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 14.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Installing collected packages: torchaudio\n","Successfully installed torchaudio-0.8.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AXMH7eltGnsM","executionInfo":{"status":"ok","timestamp":1617567964292,"user_tz":-120,"elapsed":13246,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":["import torch\n","import torchvision\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gpIfk5kLcvq","executionInfo":{"status":"ok","timestamp":1617567983949,"user_tz":-120,"elapsed":32899,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}},"outputId":"b810ba69-f2e2-4542-d604-6ae66b8c1fb4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","path = '/content/gdrive/MyDrive/Facial-Expression-Recognition.Pytorch-master/'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g4vgTq_FLl-M","executionInfo":{"status":"ok","timestamp":1617567983950,"user_tz":-120,"elapsed":32893,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":["#model = torch.load(path)\n","#example_input = torch.rand(1, 48, 48) \n","#traced_model = torch.jit.trace(model, example_input)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7boViZaf0pU","executionInfo":{"status":"ok","timestamp":1617567986701,"user_tz":-120,"elapsed":35639,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":["os.chdir(path)\n","os.getcwd()\n","from models import *"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXkQNwSoijv5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617567998564,"user_tz":-120,"elapsed":47497,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}},"outputId":"0b41ef62-e953-4b73-d735-7470875a5075"},"source":["net = VGG('VGG19')\n","checkpoint = torch.load('model.t7')\n","net.load_state_dict(checkpoint['net'])\n","net.eval()\n"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace=True)\n","    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (25): ReLU(inplace=True)\n","    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace=True)\n","    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (35): ReLU(inplace=True)\n","    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (38): ReLU(inplace=True)\n","    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace=True)\n","    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (45): ReLU(inplace=True)\n","    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (48): ReLU(inplace=True)\n","    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (51): ReLU(inplace=True)\n","    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (53): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","  )\n","  (classifier): Linear(in_features=512, out_features=7, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Y2p9HVFOjIp0","executionInfo":{"status":"ok","timestamp":1617567998565,"user_tz":-120,"elapsed":47493,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5J6fMFIjMuv","executionInfo":{"status":"ok","timestamp":1617567998566,"user_tz":-120,"elapsed":47489,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8lw5w6Gz7h4","executionInfo":{"status":"ok","timestamp":1617567998566,"user_tz":-120,"elapsed":47485,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"wukOh5LHjsUm","executionInfo":{"status":"ok","timestamp":1617567998567,"user_tz":-120,"elapsed":47482,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivcQK8IMvMUU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617568002104,"user_tz":-120,"elapsed":51013,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}},"outputId":"f6dcbc72-0593-4f67-8cdd-ba277d53071e"},"source":["from PIL import Image\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","\n","import transforms as transforms\n","path = '/content/gdrive/MyDrive/Facial-Expression-Recognition.Pytorch-master/'\n","os.chdir(path)\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","from torch.autograd import Variable\n","\n","import transforms as transforms\n","from skimage import io\n","from skimage.transform import resize\n","from models import *\n","\n","cut_size = 48\n","\n","transform_test = transforms.Compose([\n","    transforms.TenCrop(cut_size),\n","    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n","])\n","\n","def rgb2gray(rgb):\n","    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n","\n","raw_img = io.imread('sadgirl.jpg')\n","gray = rgb2gray(raw_img)\n","gray = resize(gray, (48,48), mode='symmetric').astype(np.uint8)\n","\n","img = gray[:, :, np.newaxis]\n","\n","img = np.concatenate((img, img, img), axis=2)\n","img = Image.fromarray(img)\n","inputs = transform_test(img)\n","\n","class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","\n","net.eval()\n","\n","ncrops, c, h, w = np.shape(inputs)\n","\n","inputs = inputs.view(-1, c, h, w)\n","#inputs = inputs.cuda()\n","inputs = Variable(inputs, volatile=True)\n","#print(inputs)\n","example_input = inputs\n","outputs = net(inputs)\n","\n","outputs_avg = outputs.view(ncrops, -1).mean(0)  # avg over crops\n","print(outputs_avg)\n","\n","score = F.softmax(outputs_avg)\n","_, predicted = torch.max(outputs_avg.data, 0)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["tensor([ 0.2495, -1.5129,  1.0377, -0.6874,  0.7285, -0.0569,  0.3438],\n","       grad_fn=<MeanBackward1>)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owB1RFfCwncd","executionInfo":{"status":"ok","timestamp":1617568012270,"user_tz":-120,"elapsed":61174,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}},"outputId":"cb9a8627-789d-4418-d40a-bc92e798a6a8"},"source":["\n","# Trace with random data\n","example_input = torch.rand(1,3, 48, 48) # after test, will get 'size mismatch' error message with size 256x256\n","model = torch.jit.trace(net, example_input)\n","emo_idx2label = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","\n","import coremltools as ct\n","#Convert to Core ML using the Unified Conversion API\n","# res_model = ct.convert(\n","#     model,\n","#     inputs=[ct.TensorType(name=\"image\", shape=example_input.shape)],\n","#     classifier_config=ct.ClassifierConfig(emo_idx2label)\n","# )\n","res_model = ct.convert(\n","    model,\n","    inputs=[ct.ImageType(name=\"image\", shape=(example_input.shape), scale=1/255.0)],\n","    classifier_config=ct.ClassifierConfig(emo_idx2label)\n",")\n","# res_model = ct.convert(\n","#     model,\n","#     inputs=[ct.TensorType(name=\"input\", shape=(example_input.shape))],\n","#     classifier_config=ct.ClassifierConfig(emo_idx2label)\n","# )\n","\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:root:scikit-learn version 0.22.2.post1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n","WARNING:root:TensorFlow version 2.4.1 detected. Last version known to be fully compatible is 2.3.1 .\n","WARNING:root:Keras version 2.4.3 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n","Converting Frontend ==> MIL Ops:  96%|█████████▋| 156/162 [00:00<00:00, 1289.88 ops/s]\n","Running MIL optimization passes: 100%|██████████| 18/18 [00:00<00:00, 166.43 passes/s]\n","Translating MIL ==> MLModel Ops: 100%|██████████| 246/246 [00:02<00:00, 98.43 ops/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-utXKVOSzVym","executionInfo":{"status":"ok","timestamp":1617568012271,"user_tz":-120,"elapsed":61166,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"YB5nCIO4j_6p","executionInfo":{"status":"ok","timestamp":1617568014097,"user_tz":-120,"elapsed":62985,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":["res_model.save(\"myvgg5.mlmodel\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BizoxYxxESeN","executionInfo":{"status":"ok","timestamp":1617568015001,"user_tz":-120,"elapsed":63875,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}},"outputId":"01ae8c2e-e993-42d9-dc54-2ef20956c786"},"source":["import coremltools\n","import coremltools.proto.FeatureTypes_pb2 as ft \n","\n","spec = coremltools.utils.load_spec(\"myvgg5.mlmodel\")\n","print(spec.description)\n","input = spec.description.input[0]\n","input.type.imageType.colorSpace = ft.ImageFeatureType.GRAYSCALE\n","\n","coremltools.utils.save_spec(spec, \"YourNewModel.mlmodel\")\n","print(spec.description)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["input {\n","  name: \"image\"\n","  type {\n","    imageType {\n","      width: 48\n","      height: 48\n","      colorSpace: RGB\n","    }\n","  }\n","}\n","output {\n","  name: \"260\"\n","  type {\n","    dictionaryType {\n","      stringKeyType {\n","      }\n","    }\n","  }\n","}\n","output {\n","  name: \"classLabel\"\n","  type {\n","    stringType {\n","    }\n","  }\n","}\n","predictedFeatureName: \"classLabel\"\n","predictedProbabilitiesName: \"260\"\n","metadata {\n","  userDefined {\n","    key: \"com.github.apple.coremltools.source\"\n","    value: \"torch==1.8.1+cu101\"\n","  }\n","  userDefined {\n","    key: \"com.github.apple.coremltools.version\"\n","    value: \"4.1\"\n","  }\n","}\n","\n","input {\n","  name: \"image\"\n","  type {\n","    imageType {\n","      width: 48\n","      height: 48\n","      colorSpace: GRAYSCALE\n","    }\n","  }\n","}\n","output {\n","  name: \"260\"\n","  type {\n","    dictionaryType {\n","      stringKeyType {\n","      }\n","    }\n","  }\n","}\n","output {\n","  name: \"classLabel\"\n","  type {\n","    stringType {\n","    }\n","  }\n","}\n","predictedFeatureName: \"classLabel\"\n","predictedProbabilitiesName: \"260\"\n","metadata {\n","  userDefined {\n","    key: \"com.github.apple.coremltools.source\"\n","    value: \"torch==1.8.1+cu101\"\n","  }\n","  userDefined {\n","    key: \"com.github.apple.coremltools.version\"\n","    value: \"4.1\"\n","  }\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s5mPqCKYzWnu","executionInfo":{"status":"ok","timestamp":1617568015001,"user_tz":-120,"elapsed":63867,"user":{"displayName":"jue huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9Lki9X_1XRoObwX9xJ290eOWmVj1G171OPZtV=s64","userId":"06932648507265649131"}}},"source":[""],"execution_count":11,"outputs":[]}]}